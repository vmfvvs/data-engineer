{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current spark version is 2.4.4\n"
     ]
    }
   ],
   "source": [
    "println(s\"Current spark version is ${spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|800000|\n",
      "|    0|800000|\n",
      "+-----+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dataSchema = StructType(StructField(target,IntegerType,true), StructField(id,LongType,true), StructField(raw_timestamp,StringType,true), StructField(query_status,StringType,true), StructField(author,StringType,true), StructField(tweet,StringType,true))\n",
       "dataPath = /home/jovyan/data/training.1600000.processed.noemoticon.csv\n",
       "raw_sentiment = [label: int, tweet: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[label: int, tweet: string]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructType, StructField, IntegerType, LongType, StringType}\n",
    "\n",
    "val dataSchema = new StructType()\n",
    "    .add(\"target\", IntegerType)\n",
    "    .add(\"id\", LongType)\n",
    "    .add(\"raw_timestamp\", StringType)\n",
    "    .add(\"query_status\", StringType)\n",
    "    .add(\"author\", StringType)\n",
    "    .add(\"tweet\", StringType)\n",
    "\n",
    "    \n",
    "val dataPath= \"/home/jovyan/data/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "val raw_sentiment = spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\",false)\n",
    "    .schema(dataSchema)\n",
    "    .load(dataPath)\n",
    "    .selectExpr(\"(case when target=4 then 1 else 0 end) as label\",\"tweet\")\n",
    "\n",
    "raw_sentiment.groupBy($\"label\").count.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seed = 12345\n",
       "splits = Array([label: int, tweet: string], [label: int, tweet: string])\n",
       "trainingData = [label: int, tweet: string]\n",
       "testData = [label: int, tweet: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[label: int, tweet: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val seed = 12345\n",
    "    val splits = raw_sentiment.randomSplit(Array(0.60, 0.40), seed)\n",
    "    val (trainingData, testData) = (splits(0), splits(1))\n",
    "\n",
    "    trainingData.cache\n",
    "    testData.cache    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer = tok_1b30f7229375\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "hashingTF: org.apache.spark.ml.feature.HashingT...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tok_1b30f7229375"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.tuning.{ ParamGridBuilder, CrossValidator }\n",
    "import org.apache.spark.ml.regression.{RandomForestRegressor, RandomForestRegressionModel}\n",
    "import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n",
    "import org.apache.spark.ml.feature.{HashingTF, Tokenizer}\n",
    "import org.apache.spark.ml.linalg.Vector\n",
    "import org.apache.spark.sql.Row\n",
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "import org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder, CrossValidatorModel, TrainValidationSplit}\n",
    "\n",
    "val tokenizer = new Tokenizer()\n",
    "    .setInputCol(\"tweet\")\n",
    "    .setOutputCol(\"words\")\n",
    "\n",
    "val hashingTF = new HashingTF()\n",
    "    .setNumFeatures(1000)\n",
    "    .setInputCol(tokenizer.getOutputCol)\n",
    "    .setOutputCol(\"features\")\n",
    "\n",
    "\n",
    "val rf = new RandomForestClassifier()\n",
    "    .setLabelCol(\"label\")\n",
    "    .setFeaturesCol(\"features\")\n",
    "    .setNumTrees(50)\n",
    "    \n",
    "   \n",
    "\n",
    "val pipeline = new Pipeline()\n",
    "  .setStages(Array(tokenizer, hashingTF, rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paramGrid = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array({\n",
       "\trfc_32cbc25853a8-featureSubsetStrategy: auto,\n",
       "\trfc_32cbc25853a8-impurity: gini,\n",
       "\trfc_32cbc25853a8-maxBins: 2,\n",
       "\trfc_32cbc25853a8-maxDepth: 5,\n",
       "\trfc_32cbc25853a8-numTrees: 10\n",
       "}, {\n",
       "\trfc_32cbc25853a8-featureSubsetStrategy: auto,\n",
       "\trfc_32cbc25853a8-impurity: gini,\n",
       "\trfc_32cbc25853a8-maxBins: 2,\n",
       "\trfc_32cbc25853a8-maxDepth: 10,\n",
       "\trfc_32cbc25853a8-numTrees: 10\n",
       "}, {\n",
       "\trfc_32cbc25853a8-featureSubsetStrategy: auto,\n",
       "\trfc_32cbc25853a8-impurity: gini,\n",
       "\trfc_32cbc25853a8-maxBins: 2,\n",
       "\trfc_32cbc25853a8-maxDepth: 15,\n",
       "\trfc_32cbc25853a8-numTrees: 10\n",
       "}, {\n",
       "\trfc_32cbc25853a8-featureSubsetStrategy: auto,\n",
       "\trfc_32cbc25853a8-impurity: entropy,\n",
       "\trfc_32cbc25853a8-maxBins: 2,\n",
       "\trfc_32cbc25853a8-maxDepth: 5,\n",
       "\trfc_32cbc25853a8-numTrees: 10\n",
       "}, {\n",
       "\trfc_32cbc25853a8...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val paramGrid = new ParamGridBuilder()\n",
    "      .addGrid(rf.maxDepth, 5 :: 10 :: 15 :: Nil)\n",
    "      .addGrid(rf.featureSubsetStrategy, \"auto\" :: \"all\" :: Nil)\n",
    "      .addGrid(rf.impurity, \"gini\" :: \"entropy\":: Nil)\n",
    "      .addGrid(rf.maxBins, 2 :: 5 :: 10 :: Nil)\n",
    "      .addGrid(rf.numTrees, 10 :: 50 :: Nil)\n",
    "      .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model = pipeline_71e179e87a45\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_71e179e87a45"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = pipeline.fit(raw_sentiment).asInstanceOf[PipelineModel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write.overwrite().save(\"/home/jovyan/models/spark-ml-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sameModel = pipeline_71e179e87a45\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_71e179e87a45"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sameModel = PipelineModel.load(\"/home/jovyan/models/spark-ml-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|               tweet|               words|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|    0|@switchfoot http:...|[@switchfoot, htt...|(1000,[7,14,21,54...|[23.4074465558413...|[0.46814893111682...|       1.0|\n",
      "|    0|is upset that he ...|[is, upset, that,...|(1000,[170,193,22...|[25.4201345206550...|[0.50840269041310...|       0.0|\n",
      "|    0|@Kenichan I dived...|[@kenichan, i, di...|(1000,[10,36,77,1...|[27.4328870945118...|[0.54865774189023...|       0.0|\n",
      "|    0|my whole body fee...|[my, whole, body,...|(1000,[82,191,296...|[25.5825291770754...|[0.51165058354150...|       0.0|\n",
      "|    0|@nationwideclass ...|[@nationwideclass...|(1000,[18,96,130,...|[27.3528875090967...|[0.54705775018193...|       0.0|\n",
      "|    0|@Kwesidei not the...|[@kwesidei, not, ...|(1000,[18,223,710...|[25.3108566551697...|[0.50621713310339...|       0.0|\n",
      "|    0|         Need a hug |      [need, a, hug]|(1000,[48,170,537...|[24.1646023534122...|[0.48329204706824...|       1.0|\n",
      "|    0|@LOLTrish hey  lo...|[@loltrish, hey, ...|(1000,[139,157,17...|[23.1531937018541...|[0.46306387403708...|       1.0|\n",
      "|    0|@Tatiana_K nope t...|[@tatiana_k, nope...|(1000,[48,234,299...|[24.5995754015919...|[0.49199150803183...|       1.0|\n",
      "|    0|@twittera que me ...|[@twittera, que, ...|(1000,[161,324,47...|[24.1445133114613...|[0.48289026622922...|       1.0|\n",
      "|    0|spring break in p...|[spring, break, i...|(1000,[13,193,301...|[24.0777855402013...|[0.48155571080402...|       1.0|\n",
      "|    0|I just re-pierced...|[i, just, re-pier...|(1000,[307,329,47...|[26.2489084890936...|[0.52497816978187...|       0.0|\n",
      "|    0|@caregiving I cou...|[@caregiving, i, ...|(1000,[56,202,234...|[26.6642593518631...|[0.53328518703726...|       0.0|\n",
      "|    0|@octolinz16 It it...|[@octolinz16, it,...|(1000,[126,230,32...|[24.3603446702632...|[0.48720689340526...|       1.0|\n",
      "|    0|@smarrison i woul...|[@smarrison, i, w...|(1000,[18,83,170,...|[27.4569841595863...|[0.54913968319172...|       0.0|\n",
      "|    0|@iamjazzyfizzle I...|[@iamjazzyfizzle,...|(1000,[7,71,202,2...|[27.1426108610684...|[0.54285221722136...|       0.0|\n",
      "|    0|Hollis' death sce...|[hollis', death, ...|(1000,[2,3,18,82,...|[25.7709725653821...|[0.51541945130764...|       0.0|\n",
      "|    0|about to file taxes |[about, to, file,...|(1000,[108,388,48...|[24.2831747074441...|[0.48566349414888...|       1.0|\n",
      "|    0|@LettyA ahh ive a...|[@lettya, ahh, iv...|(1000,[13,107,201...|[22.4163559498907...|[0.44832711899781...|       1.0|\n",
      "|    0|@FakerPattyPattz ...|[@fakerpattypattz...|(1000,[53,102,154...|[22.8831636202212...|[0.45766327240442...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predictionsDF = [label: int, tweet: string ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[label: int, tweet: string ... 5 more fields]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictionsDF = sameModel.transform(raw_sentiment)\n",
    "\n",
    "predictionsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getProbability = UserDefinedFunction(<function1>,DoubleType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function1>,DoubleType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val getProbability = udf((prediction: org.apache.spark.ml.linalg.Vector) => prediction(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|  clean_probability|\n",
      "+-------------------+\n",
      "| 0.5318510688831722|\n",
      "| 0.4915973095868992|\n",
      "| 0.4513422581097638|\n",
      "|0.48834941645849084|\n",
      "|  0.452942249818065|\n",
      "|  0.493782866896605|\n",
      "| 0.5167079529317546|\n",
      "| 0.5369361259629176|\n",
      "| 0.5080084919681612|\n",
      "|  0.517109733770774|\n",
      "| 0.5184442891959721|\n",
      "| 0.4750218302181278|\n",
      "|0.46671481296273626|\n",
      "| 0.5127931065947351|\n",
      "|0.45086031680827354|\n",
      "| 0.4571477827786316|\n",
      "|0.48458054869235645|\n",
      "|  0.514336505851116|\n",
      "| 0.5516728810021843|\n",
      "| 0.5423367275955744|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionsDF.select(getProbability($\"probability\").alias(\"clean_probability\")).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
